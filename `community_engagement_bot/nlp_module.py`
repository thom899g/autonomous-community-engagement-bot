from typing import Optional, List
import logging
from transformers import AutoModelForCausalLM, AutoTokenizer

logger = logging.getLogger(__name__)

class TextGenerator:
    def __init__(self, model_path: str):
        self.model = None
        self.tokenizer = None
        self._load_model(model_path)
        
    def _load_model(self, model_path: str) -> None:
        """Load NLP model and tokenizer."""
        try:
            self.model = AutoModelForCausalLM.from_pretrained(model_path)
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            logger.info(f"Loaded NLP model from {model_path}")
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            raise

    def generate_response(self, input_text: str, sentiment: Optional[str] = None) -> str:
        """Generate a response based on input and sentiment."""
        try:
            # Annotate for type checking
            assert isinstance(input_text, str)
            
            inputs = self.tokenizer.encode(input_text, return_tensors='pt', max_length=512)
            outputs = self.model.generate(inputs, max_length=500, temperature=0.7)
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            logger.debug(f"Generated response: {response}")
            
            return response
        except Exception as e:
            logger.error(f"Failed to generate response: {e}")
            raise

    def _handle_error(self, error: Exception) -> None:
        """Helper method for consistent error handling."""
        logger.error(f"Error in NLP generation: {str(error)}")